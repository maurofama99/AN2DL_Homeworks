{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOi36o91kVS5+bUB3obSann",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maurofama99/ann_challenge/blob/main/final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANNDL Challenge 1"
      ],
      "metadata": {
        "id": "iuqF3A-Y8ywo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set Up"
      ],
      "metadata": {
        "id": "ohwX_IvtHDwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to google drive"
      ],
      "metadata": {
        "id": "7NJeMPynGJy1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2tm8Z3W78BL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go inside the folder"
      ],
      "metadata": {
        "id": "eypgr-_MGQx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /gdrive/My Drive/"
      ],
      "metadata": {
        "id": "tIHpmBTe89Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "P2X8HgiH9EUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm\n",
        "from PIL import Image\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "haiBDM7K89F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seed for reproducivity"
      ],
      "metadata": {
        "id": "w27j6__x9OAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "metadata": {
        "id": "xehkYonB9SvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppress warnings"
      ],
      "metadata": {
        "id": "PvQ3BXWR9YyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "tf.get_logger().setLevel('INFO')\n",
        "tf.autograph.set_verbosity(0)\n",
        "\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "metadata": {
        "id": "feIBsOE29qPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funtions to test the model on validation set and plot the confusion matrix"
      ],
      "metadata": {
        "id": "o63GBQcH_jOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusionMatrix(test_labels, test_predicted):\n",
        "  \n",
        "  cm = confusion_matrix(test_labels, test_predicted, labels=[0,1,2,3,4,5,6,7])\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                display_labels=labels)\n",
        "  disp.plot()\n",
        "  plt.show()\n",
        "  return "
      ],
      "metadata": {
        "id": "i5BsKgcR_XlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testModel( valid_gen, model):\n",
        "\n",
        "  # Predit test labels\n",
        "  test_predicted = model.predict(valid_gen)\n",
        "  test_predicted = np.argmax(test_predicted, axis=-1)\n",
        "  \n",
        "  # plot confusion matrix\n",
        "  plot_confusionMatrix(valid_gen.classes, test_predicted)\n",
        "\n",
        "  # display classification results\n",
        "  print(classification_report(valid_gen.classes, test_predicted, target_names=labels))"
      ],
      "metadata": {
        "id": "YXHTb0sq_XWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset folders \n",
        "dataset_dir = 'training_data_final'"
      ],
      "metadata": {
        "id": "8ox8DVCe-TQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the number of img of each species\n",
        "import fnmatch\n",
        "\n",
        "count = [0,0,0,0,0,0,0,0]   # where I store the amount of images for each species\n",
        "labels = ['Species1',       # 0\n",
        "          'Species2',       # 1\n",
        "          'Species3',       # 2\n",
        "          'Species4',       # 3\n",
        "          'Species5',       # 4\n",
        "          'Species6',       # 5\n",
        "          'Species7',       # 6\n",
        "          'Species8']       # 7\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  dir_path = os.path.join(dataset_dir, labels[i])\n",
        "  count[i] = len(fnmatch.filter(os.listdir(dir_path), '*.*'))\n",
        "  print('The number of img of', labels[i], 'is: ', count[i])\n",
        "\n",
        "cumsum = np.cumsum(count)\n",
        "print('Total amount of img is: ', cumsum[len(cumsum)-1] )"
      ],
      "metadata": {
        "id": "mU_4HZl1-aJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split data in train and test\n",
        "Split the dataset in train (80%) and validation (20%) \\\\\n",
        "Also apply as augmentations: \n",
        "- rotation (30)\n",
        "- shift (50)\n",
        "- zoom (0.3)\n",
        "- horizontal flip\n",
        "- vertical flip"
      ],
      "metadata": {
        "id": "3d2cm27NEZYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Images are divided into folders, one for each class. \n",
        "# If the images are organized in such a way, we can exploit the ImageDataGenerator to read them from disk.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator with Data Augmentation\n",
        "valid_data_gen = ImageDataGenerator(rescale=1/255, validation_split=0.2) \n",
        "\n",
        "train_data_gen = ImageDataGenerator(rotation_range=30,\n",
        "                                        height_shift_range=50,\n",
        "                                        width_shift_range=50,\n",
        "                                        zoom_range=0.3,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=True, \n",
        "                                        fill_mode='reflect',\n",
        "                                        rescale=1/255,\n",
        "                                        validation_split=0.2)\n",
        "\n",
        "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
        "train_gen = train_data_gen.flow_from_directory(directory=dataset_dir,\n",
        "                                                           target_size=(96,96),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None, \n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=32,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed,\n",
        "                                                           subset=\"training\")\n",
        "\n",
        "valid_gen = valid_data_gen.flow_from_directory(directory=dataset_dir,\n",
        "                                               target_size=(96,96),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=None, \n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=1,\n",
        "                                               shuffle=False,\n",
        "                                               seed=seed,\n",
        "                                               subset=\"validation\")"
      ],
      "metadata": {
        "id": "ssdUV1Di_XIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (96, 96, 3)\n",
        "epochs = 200"
      ],
      "metadata": {
        "id": "2VqNY_jlGE-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build Model"
      ],
      "metadata": {
        "id": "AaFuLv_VG495"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_1(input_shape, convnet):\n",
        "\n",
        "  dropout_rate = 0.2\n",
        "  dropout_rate1 = 0.5\n",
        "\n",
        "  # Build the model layer by layer\n",
        "  input_layer = convnet.layers[0].input\n",
        "  flat1 = Flatten()(convnet.layers[-1].output)\n",
        "  flat1 = tfkl.Dropout(dropout_rate, seed=seed)(flat1)\n",
        "  hidden_layer1 = tfkl.Dense(units=512, activation='relu', name='Hidden1', \n",
        "                                kernel_initializer=tfk.initializers.HeUniform(seed=seed))(flat1)\n",
        "  hidden_layer1 = tfkl.Dropout(dropout_rate, seed=seed)(hidden_layer1)\n",
        "  hidden_layer2 = tfkl.Dense(units=256, activation='relu', name='Hidden2', \n",
        "                                kernel_initializer=tfk.initializers.HeUniform(seed=seed))(hidden_layer1)\n",
        "  hidden_layer2 = tfkl.Dropout(dropout_rate1, seed=seed)(hidden_layer2)\n",
        "  output = tfkl.Dense(units=8, activation='softmax', name='Output', \n",
        "                                kernel_initializer=tfk.initializers.HeUniform(seed=seed))(hidden_layer2)\n",
        "  \n",
        "  # Connect input and output through the Model class\n",
        "  model = tfk.Model(inputs=input_layer, outputs=output, name='model')\n",
        "\n",
        "  # Compile the model\n",
        "  learning_rate = 1e-5\n",
        "  opt = tfk.optimizers.Adam(learning_rate)\n",
        "\n",
        "  model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=opt, metrics='accuracy')\n",
        "\n",
        "  # Return the model\n",
        "  return model"
      ],
      "metadata": {
        "id": "BIUOICRaHHuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_2(input_shape, supernet):\n",
        "\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    xc_layer = supernet(input_layer) \n",
        "\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(xc_layer)\n",
        "\n",
        "    layer1 = tfkl.Dense(units=512, kernel_initializer = tfk.initializers.HeUniform(seed), activation='relu')(flattening_layer)\n",
        "\n",
        "    dropout1 = tfkl.Dropout(0.2, seed=seed)(layer1)\n",
        "\n",
        "    classifier_layer = tfkl.Dense(units=256, name='Classifier', kernel_initializer = tfk.initializers.HeUniform(seed), activation='relu')(dropout1)\n",
        "\n",
        "    dropout2 = tfkl.Dropout(0.5, seed=seed)(classifier_layer)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(dropout2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-3), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ],
      "metadata": {
        "id": "pFhiyK6SIE9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_3(input_shape, convnet):\n",
        "\n",
        "  # Build the model\n",
        "  input_layer = convnet.layers[0].input\n",
        "  flat1 = Flatten()(convnet.layers[-1].output)\n",
        "  hidden_layer1 = tfkl.Dense(units=700, activation='relu', name='Hidden1', \n",
        "                                kernel_initializer=tfk.initializers.HeUniform(seed=seed))(flat1)\n",
        "  hidden_layer2 = tfkl.Dense(units=350, activation='relu', name='Hidden2', \n",
        "                                kernel_initializer=tfk.initializers.HeUniform(seed=seed))(hidden_layer1)\n",
        "  output = tfkl.Dense(units=8, activation='softmax', name='Output', \n",
        "                                kernel_initializer=tfk.initializers.HeUniform(seed=seed))(hidden_layer2)\n",
        "  \n",
        "  # Connect input and output through the Model class\n",
        "  model = tfk.Model(inputs=input_layer, outputs=output, name='model')\n",
        "\n",
        "  \n",
        "  # Compile the model\n",
        "  learning_rate = 1e-4\n",
        "  opt = tfk.optimizers.Adam(learning_rate)\n",
        "  model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=opt, metrics='accuracy')\n",
        "  \n",
        "  # Return the model\n",
        "  return model"
      ],
      "metadata": {
        "id": "nwnHeemwNpcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Callbacks"
      ],
      "metadata": {
        "id": "IzlPn9aTI0GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to create folders and callbacks for training\n",
        "from datetime import datetime\n",
        "\n",
        "def create_folders_and_callbacks(model_name):\n",
        "\n",
        "  exps_dir = os.path.join('experiments')\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "      \n",
        "  callbacks = []\n",
        "\n",
        "  # Model checkpoint\n",
        "  # ----------------\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
        "                                                     save_weights_only=True, # True to save only weights\n",
        "                                                     save_best_only=False) # True to save only the best epoch \n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Visualize Learning on Tensorboard\n",
        "  # ---------------------------------\n",
        "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "  if not os.path.exists(tb_dir):\n",
        "      os.makedirs(tb_dir)\n",
        "      \n",
        "  # By default shows losses and metrics for both training and validation\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
        "                                               profile_batch=0,\n",
        "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
        "  callbacks.append(tb_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  # --------------\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "  callbacks.append(es_callback)\n",
        "\n",
        "  return callbacks"
      ],
      "metadata": {
        "id": "H7caiag_Iy-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 1\n",
        "VGG16 architecture"
      ],
      "metadata": {
        "id": "koashV-YJIVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg16 = VGG16(include_top=False, input_shape=inputshape)"
      ],
      "metadata": {
        "id": "A5K3RF6oJQ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train all the layer, even the ones of the pre-trained model"
      ],
      "metadata": {
        "id": "uPbajj-zKVj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "\tlayer.trainable = True"
      ],
      "metadata": {
        "id": "yTwFY2VGKTQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model and visualize it\n",
        "model_1 = build_model_1(input_shape, vgg16)\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "2UVgX6APJsvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders and callbacks and fit\n",
        "callbacks = create_folders_and_callbacks(model_name='CNN_VGG16')\n",
        "\n",
        "# Train the model\n",
        "history = model_1.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen,\n",
        "    class_weight = {0: 3542/186, 1: 3542/532, 2: 3542/515, 3: 3542/511, 4: 3542/531, \n",
        "                    5: 3542/222, 6: 3542/537, 7: 3542/508},\n",
        "    callbacks = callbacks,\n",
        ").history"
      ],
      "metadata": {
        "id": "snDFE7KdK43s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best epoch model\n",
        "model_1.save(\"savedModels/CNN_VGG16\")"
      ],
      "metadata": {
        "id": "B9dqMZvnLBqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(valid_gen, model_1)"
      ],
      "metadata": {
        "id": "5F2Dn_BFLBkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 2\n",
        "XCeption architecture"
      ],
      "metadata": {
        "id": "NFQcOTapLja0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xCeption = tfk.applications.Xception(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(96,96,3)\n",
        ")"
      ],
      "metadata": {
        "id": "gvfD2SfYLgx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train only the fully connected layers (which are not part of the pre-trained model)"
      ],
      "metadata": {
        "id": "SjDX2OuFMHsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in xCeption.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "mmcfMlYPLqjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = build_model_2(input_shape, xCeption)\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "DYMdk2-cLqf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = create_folders_and_callbacks(model_name='CNN_XCeption')\n",
        "\n",
        "# Train the model\n",
        "history = model2.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen,\n",
        "    class_weight = {0: 3542/186, 1: 3542/532, 2: 3542/515, 3: 3542/511, 4: 3542/531, \n",
        "                    5: 3542/222, 6: 3542/537, 7: 3542/508},\n",
        "    callbacks = callbacks,\n",
        ").history"
      ],
      "metadata": {
        "id": "1xRKNLzcMagR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best epoch model\n",
        "model2.save(\"savedModels/CNN_XCeption\")"
      ],
      "metadata": {
        "id": "BWBfU2XdMtej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(valid_gen, model2)"
      ],
      "metadata": {
        "id": "fqGEqY6EMtYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then perform Fine tuing by unfreezing the layers of the xception architecture and re train the hole model with a lower learning rate"
      ],
      "metadata": {
        "id": "Uje7f-dbM4e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tfk.models.load_model(\"savedModels/CNN_XCeption\")"
      ],
      "metadata": {
        "id": "n_UHd_nbM33h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unfreeze the layers"
      ],
      "metadata": {
        "id": "8BS8DuauNSc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.get_layer('xception').trainable = True"
      ],
      "metadata": {
        "id": "f-QDECICM3ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "Ejx6E39NNN4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = create_folders_and_callbacks(model_name='CNN_XCeption_FineTuning')\n",
        "\n",
        "# Train the model\n",
        "history = model_2.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen,\n",
        "    class_weight = {0: 3542/186, 1: 3542/532, 2: 3542/515, 3: 3542/511, 4: 3542/531, \n",
        "                    5: 3542/222, 6: 3542/537, 7: 3542/508},\n",
        "    callbacks = callbacks,\n",
        ").history"
      ],
      "metadata": {
        "id": "pMnemJApNZK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best epoch model\n",
        "model_2.save(\"savedModels/CNN_XCeption_FineTuning\")"
      ],
      "metadata": {
        "id": "qq43OZ6YNfs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(valid_gen, model_2)"
      ],
      "metadata": {
        "id": "1wBnXfX7Nfch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 3\n",
        "VGG19 architecture"
      ],
      "metadata": {
        "id": "G7q0LKKJN_7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = tfk.applications.VGG19(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(96,96,3)\n",
        ")"
      ],
      "metadata": {
        "id": "1Y7bxq5hTgkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train only the fully connected layers (which are not part of the pre-trained model)"
      ],
      "metadata": {
        "id": "JIySsZUfT1GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "APRCaEimTgsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = build_model_3(input_shape, supernet9)\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "Fvk5_LYRTgqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = create_folders_and_callbacks(model_name='CNN_VGG19')\n",
        "\n",
        "# Train the model\n",
        "history = model3.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen,\n",
        "    class_weight = {0: 3542/186, 1: 3542/532, 2: 3542/515, 3: 3542/511, 4: 3542/531, \n",
        "                    5: 3542/222, 6: 3542/537, 7: 3542/508},\n",
        "    callbacks = callbacks,\n",
        ").history"
      ],
      "metadata": {
        "id": "eNTs32krT70D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best epoch model\n",
        "model3.save(\"savedModels/CNN_VGG19\")"
      ],
      "metadata": {
        "id": "SCkSzDVkT7xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(valid_gen, model3)"
      ],
      "metadata": {
        "id": "purE7howT7ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then perform Fine tuing by unfreezing the layers of the xception architecture and re train the hole model with a lower learning rate"
      ],
      "metadata": {
        "id": "DmeXJHvTUJqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = tfk.models.load_model(\"savedModels/CNN_VGG19\")"
      ],
      "metadata": {
        "id": "Ebx0R0C7UOGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.get_layer('vgg19').trainable = True"
      ],
      "metadata": {
        "id": "WNkA4DIzUOcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "rSuCY5wNUdAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = create_folders_and_callbacks(model_name='CNN_VGG19_FineTuning')\n",
        "\n",
        "# Train the model\n",
        "history = model_3.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen,\n",
        "    class_weight = {0: 3542/186, 1: 3542/532, 2: 3542/515, 3: 3542/511, 4: 3542/531, \n",
        "                    5: 3542/222, 6: 3542/537, 7: 3542/508},\n",
        "    callbacks = callbacks,\n",
        ").history"
      ],
      "metadata": {
        "id": "rYtjBHrQUc4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best epoch model\n",
        "model_3.save(\"savedModels/CNN_VGG19_FineTuning\")"
      ],
      "metadata": {
        "id": "8T3u4tm0UwIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(valid_gen, model_3)"
      ],
      "metadata": {
        "id": "Db_U7bFmUwF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensamble\n",
        "Combine together the tree models computing the avarage output"
      ],
      "metadata": {
        "id": "hwk5bRiGVBcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_model = tfk.models.load_model(\"savedModels/VGG16\")\n",
        "second_model = tfk.models.load_model(\"savedModels/CNN_XCeption_FineTuning\")\n",
        "third_model = tfk.models.load_model(\"savedModels/CNN_VGG19_FineTuning\")\n",
        "\n",
        "first_model._name = 'model1'\n",
        "second_model._name = 'model2'\n",
        "third_model._name = 'model3'"
      ],
      "metadata": {
        "id": "RgovdP1bVeLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [first_model, second_model, third_model]\n",
        "\n",
        "model_input = tf.keras.Input(shape=input_shape, name='input_layer')\n",
        "model_outputs = [model(model_input) for model in models]\n",
        "\n",
        "ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
        "\n",
        "ensemble_model = tf.keras.Model(inputs=model_input, outputs=ensemble_output)"
      ],
      "metadata": {
        "id": "J58nFgHOVnTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_model.summary()"
      ],
      "metadata": {
        "id": "yGVNGbz2VxMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_model.save(\"savedModels/EnsambleModel\")"
      ],
      "metadata": {
        "id": "fPTK9lpNV03n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(valid_gen, ensemble_model)"
      ],
      "metadata": {
        "id": "w0qcMgGwV0rj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}